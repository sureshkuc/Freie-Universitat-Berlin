Project1: Implementation of a k-NN-Classifier
Implement a k-NN-Classifier in Python (incl. Numpy, Pandas, Matplotlib) on the Jupyter Notebook Environment. Use the “ZIP-Code”-Dataset1 with the training data as reference
for neighborhood. Evaluate the model on the test data.
(a) Print out the accuracy.
(b) Using Matplotlib, plot some of the numbers that are classified incorrectly.
(c) Which k is optimal for the accuracy?
(d) What are advantages and disadvantages for the k-NN-Classifier?

Project2: Implementation of a DBSCAN-Classifier
Implement a DBSCAN-Clustering in Python (incl. Numpy, Matplotlib) on the Jupyter Notebook Environment. Apply the algorithm on the “Two-Spirals”-dataset given in the notebook.
Evaluate the model on points given by that distribution.
(a) Use Mathplotlib to create a scatter plot highlighting the clusters that were found after
finding good hyperparameter values eps and minPts.
(b) Print accuracies for different data_size values.
(c) For what kind of data_size values does the algorithm fail and why? What would you
say are disadvantages of DBSCAN?

Project3: Logistic Regression
Logistic Regression can be interpreted as a neural network with just one layer. It uses the
Cross Entropy to measure the performance of the layer (i.e. of the ”trained” weight w and
bias b). In ML we call this the Loss function.
Implement Logistic Regression using Python (incl. Numpy etc.) and use it on the ” ZIPCode”-Dataset 2
. Implement the Cross Entropy and the Sigmoid function from scratch. Use
gradient descent to optimize.
(a) What happens when you take the Means Squared Error (MSE) instead of the Cross
Entropy? Does this also work? Implement MSE and try for yourself.
(b) (Optional) Can you think of a way to classify more than one class (in this case 10
classes)? How would you change the way w and b is defined?

Project4: 
