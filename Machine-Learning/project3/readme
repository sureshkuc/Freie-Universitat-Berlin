Excercise: Logistic Regression
Logistic Regression can be interpreted as a neural network with just one layer. It uses the
Cross Entropy to measure the performance of the layer (i.e. of the ”trained” weight w and
bias b). In ML we call this the Loss function.
Implement Logistic Regression using Python (incl. Numpy etc.) and use it on the ” ZIPCode”-Dataset 2
. Implement the Cross Entropy and the Sigmoid function from scratch. Use
gradient descent to optimize.
(a) What happens when you take the Means Squared Error (MSE) instead of the Cross
Entropy? Does this also work? Implement MSE and try for yourself.
(b) (Optional) Can you think of a way to classify more than one class (in this case 10
classes)? How would you change the way w and b is defined?
