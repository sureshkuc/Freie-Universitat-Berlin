```markdown
# Project6: Decision Trees and Random Forests on SPAM Dataset

This project implements **Decision Trees** and **Random Forests** from scratch using Python and applies them to the [UCI Spambase Dataset](https://archive.ics.uci.edu/ml/datasets/spambase). The goal is to classify emails as spam or not spam and analyze feature importance, model performance, and misclassification costs.

## ğŸ“ Project Structure

```

project6/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py             # Configuration and constants
â”‚   â”œâ”€â”€ model.py              # Decision tree and random forest implementations
â”‚   â”œâ”€â”€ train.py              # Training logic
â”‚   â”œâ”€â”€ evaluation.py         # Evaluation metrics, confusion matrix, AUC, etc.
â”‚   â”œâ”€â”€ plot.py               # Plotting functions (feature importance, results)
â”‚   â”œâ”€â”€ utils.py              # Helper functions
â”‚   â”œâ”€â”€ main.py               # Main driver script
â”‚   â””â”€â”€ test\_model.py         # Unit tests for the model
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ feature\_imp.png       # Top 5 features by importance
â”‚   â”œâ”€â”€ auc.png               # ROC curve and AUC for random forest
â”‚   â””â”€â”€ result.png            # Model accuracy and performance summary
â”‚
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # Project documentation

````

---

## ğŸ§  Exercises Overview

### ğŸ”¹ Exercise 1: Decision Trees
- Implemented a classification decision tree using Python and NumPy.
- Custom loss function (Gini Index by default; can be changed).
- **Asymmetric Misclassification Cost**:
  - Misclassifying a **genuine email as spam** is **10Ã— worse** than the reverse.
  - This was handled by weighting the loss function during the split criterion to penalize such misclassifications.
- **Feature Importance**:
  - Top 5 most informative features were identified using node impurity reduction.
  - ğŸ“Š Visualization saved as `outputs/feature_imp.png`.

### ğŸ”¹ Exercise 2: Random Forest
- Implemented a random forest classifier using bagging and feature subsetting.
- Evaluation using:
  - âœ… Accuracy
  - ğŸ§¾ Confusion Matrix
  - ğŸ“ˆ ROC Curve & AUC (`outputs/auc.png`)
- Explored the effect of varying the number of trees on performance.
- Identified an optimal range for number of trees based on validation results.

---

## ğŸ“Š Visual Outputs

- `outputs/feature_imp.png` â€” Top 5 feature importances (based on information gain)
- `outputs/auc.png` â€” ROC curve for Random Forest
- `outputs/result.png` â€” Overall performance summary

---

## âš™ï¸ Installation & Usage

### Step 1: Clone the Repository
```bash
git clone https://github.com/sureshkuc
````

### Step 2: Set Up Environment

Install dependencies (preferably in a virtual environment):

```bash
pip install -r requirements.txt
```

### Step 3: Run the Project

Train the models and generate outputs:

```bash
python src/main.py
```

---

## ğŸ§ª Testing

Unit tests for the model logic can be run with:

```bash
python -m unittest src/test_model.py
```

---

## ğŸ“ˆ Metrics & Results

* Confusion Matrix (Random Forest):

  * True Positives, True Negatives, False Positives, False Negatives
* AUC score
* Feature importance rankings
* Performance with asymmetric costs

---

## ğŸ” Dataset

* **Source**: [UCI Spambase Dataset](https://archive.ics.uci.edu/ml/datasets/spambase)
* **Features**: 57 attributes (word frequencies, character frequencies, capital letter run lengths)
* **Label**: Spam (1) or Not Spam (0)

---

## ğŸ“Œ Future Work

* Add support for pruning in decision trees.
* Perform cross-validation to improve model selection.
* Extend to other text classification datasets.

---

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

```
