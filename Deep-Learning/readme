Project2: MNIST type prediction challenge
          You are given MNIST-type training data of images with handwritten digits. The data consists of training images with associated labels in {0,1,…,9} and an unlabeled test set.
          Your task is to train a neural network model of your choice to predict the digit from the image.
          
Project4: CIFAR type prediction challenge
          You are given CIFAR-type training data of 6000 images picturing either cats, dogs or frogs (see attached file). The data consists of training images (x_train) with associated labels (y_train) in {0=cat,1=dog, 2=frog} and an unlabeled test set (x_test). Your task is to train a neural network model to predict labels from images. As a submission, please upload your prediction of labels for the test set (x_test).
          For the presentation, be prepared to show your code, explain how you prepared the data, how you chose the network architecture and other hyperparameters, how you validated the model, and show the convergence of the training error. 
          
Project6: Dimension reduction challenge (Autoencoder)
          You are given a three-dimensional time series data: data_x∈RT×3, with T=100,000 (number of data points). The data points in this time series can be grouped/clustered into four (metastable) states which, unfortunately, cannot be separated by simple geometric means.
          Your first task is to perform a dimension reduction from the original three-dimensional representation into a one-dimensional time series in such a way that the four different states become disentangled. In other words, the four states must be easily separable in the one-dimensional representation. We recommend to use a time-lagged autoencoder for this task, but your are free to try other approaches, too.
          Hint: a proper data whitening might be very beneficial for the training.
          In the second task, you have to discretize your one-dimensional representation, i.e., all data points which seem to belong to the same (metastable) state must be assigned the same label data_y∈{0,1,2,3}. The order in which you label the metastable states is not important (we will test all combinations).
          Hint: you can do the discretization, e.g., by defining four different positions (cluster centers) within your one-dimensional dataset and assign each data point to the closest cluster center.
          For validation purposes, we have added a validation set containing 1000 data points (validation_x) and their corresponding metastable state labels (validation_y
          
Project8: RNN Challenge
          In this challenge, the gaol is to train a classifier for sequences of genetic code.
          Each sequence is represented by a string of letters [‘A’, ‘C’, ‘G’, ’T’] and belongs to one of five categories/classes labelled [0,…,4].
          For training purposes, you will find 400 labelled sequences, each of length 400 characters (sequences: data_x, labels: data_y).
          To validate your model, you have a further 100 labelled sequences (val_x, val_y) with 1200 characters each.
          Finally, you have 250 unlabeled sequences (test_x, 2000 characters) which need to be classified.
          Hint: Training recurrent networks is very expensive! Do not start working on this challenge too late or you might not manage to finish in time.
          Your task is to train an RNN-based classifier and make a prediction for the missing labels of the test set (test_x in the attached archive).
